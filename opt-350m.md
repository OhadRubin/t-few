|     | module                      | c_name               | layer                                                                        | should_modify   | is_linear   |
|----:|:----------------------------|:---------------------|:-----------------------------------------------------------------------------|:----------------|:------------|
|   0 |                             | decoder              | <class 'transformers.models.opt.modeling_opt.OPTDecoder'>                    | False           | False       |
|   1 | decoder                     | embed_tokens         | <class 'torch.nn.modules.sparse.Embedding'>                                  | False           | False       |
|   2 | decoder                     | embed_positions      | <class 'transformers.models.opt.modeling_opt.OPTLearnedPositionalEmbedding'> | False           | False       |
|   3 | decoder                     | project_out          | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|   4 | decoder                     | project_in           | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|   5 | decoder                     | layers               | <class 'torch.nn.modules.container.ModuleList'>                              | False           | False       |
|   6 | decoder.layers              | 0                    | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|   7 | decoder.layers              | 1                    | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|   8 | decoder.layers              | 2                    | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|   9 | decoder.layers              | 3                    | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  10 | decoder.layers              | 4                    | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  11 | decoder.layers              | 5                    | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  12 | decoder.layers              | 6                    | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  13 | decoder.layers              | 7                    | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  14 | decoder.layers              | 8                    | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  15 | decoder.layers              | 9                    | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  16 | decoder.layers              | 10                   | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  17 | decoder.layers              | 11                   | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  18 | decoder.layers              | 12                   | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  19 | decoder.layers              | 13                   | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  20 | decoder.layers              | 14                   | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  21 | decoder.layers              | 15                   | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  22 | decoder.layers              | 16                   | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  23 | decoder.layers              | 17                   | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  24 | decoder.layers              | 18                   | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  25 | decoder.layers              | 19                   | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  26 | decoder.layers              | 20                   | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  27 | decoder.layers              | 21                   | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  28 | decoder.layers              | 22                   | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  29 | decoder.layers              | 23                   | <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>               | False           | False       |
|  30 | decoder.layers.0            | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
|  31 | decoder.layers.0            | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
|  32 | decoder.layers.0            | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
|  33 | decoder.layers.0            | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  34 | decoder.layers.0            | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  35 | decoder.layers.0            | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
|  36 | decoder.layers.0.self_attn  | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  37 | decoder.layers.0.self_attn  | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  38 | decoder.layers.0.self_attn  | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  39 | decoder.layers.0.self_attn  | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  40 | decoder.layers.1            | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
|  41 | decoder.layers.1            | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
|  42 | decoder.layers.1            | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
|  43 | decoder.layers.1            | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  44 | decoder.layers.1            | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  45 | decoder.layers.1            | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
|  46 | decoder.layers.1.self_attn  | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  47 | decoder.layers.1.self_attn  | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  48 | decoder.layers.1.self_attn  | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  49 | decoder.layers.1.self_attn  | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  50 | decoder.layers.2            | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
|  51 | decoder.layers.2            | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
|  52 | decoder.layers.2            | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
|  53 | decoder.layers.2            | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  54 | decoder.layers.2            | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  55 | decoder.layers.2            | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
|  56 | decoder.layers.2.self_attn  | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  57 | decoder.layers.2.self_attn  | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  58 | decoder.layers.2.self_attn  | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  59 | decoder.layers.2.self_attn  | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  60 | decoder.layers.3            | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
|  61 | decoder.layers.3            | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
|  62 | decoder.layers.3            | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
|  63 | decoder.layers.3            | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  64 | decoder.layers.3            | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  65 | decoder.layers.3            | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
|  66 | decoder.layers.3.self_attn  | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  67 | decoder.layers.3.self_attn  | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  68 | decoder.layers.3.self_attn  | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  69 | decoder.layers.3.self_attn  | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  70 | decoder.layers.4            | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
|  71 | decoder.layers.4            | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
|  72 | decoder.layers.4            | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
|  73 | decoder.layers.4            | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  74 | decoder.layers.4            | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  75 | decoder.layers.4            | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
|  76 | decoder.layers.4.self_attn  | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  77 | decoder.layers.4.self_attn  | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  78 | decoder.layers.4.self_attn  | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  79 | decoder.layers.4.self_attn  | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  80 | decoder.layers.5            | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
|  81 | decoder.layers.5            | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
|  82 | decoder.layers.5            | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
|  83 | decoder.layers.5            | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  84 | decoder.layers.5            | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  85 | decoder.layers.5            | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
|  86 | decoder.layers.5.self_attn  | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  87 | decoder.layers.5.self_attn  | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  88 | decoder.layers.5.self_attn  | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  89 | decoder.layers.5.self_attn  | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  90 | decoder.layers.6            | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
|  91 | decoder.layers.6            | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
|  92 | decoder.layers.6            | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
|  93 | decoder.layers.6            | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  94 | decoder.layers.6            | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  95 | decoder.layers.6            | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
|  96 | decoder.layers.6.self_attn  | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  97 | decoder.layers.6.self_attn  | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
|  98 | decoder.layers.6.self_attn  | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
|  99 | decoder.layers.6.self_attn  | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 100 | decoder.layers.7            | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
| 101 | decoder.layers.7            | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
| 102 | decoder.layers.7            | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 103 | decoder.layers.7            | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 104 | decoder.layers.7            | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 105 | decoder.layers.7            | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 106 | decoder.layers.7.self_attn  | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 107 | decoder.layers.7.self_attn  | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 108 | decoder.layers.7.self_attn  | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 109 | decoder.layers.7.self_attn  | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 110 | decoder.layers.8            | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
| 111 | decoder.layers.8            | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
| 112 | decoder.layers.8            | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 113 | decoder.layers.8            | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 114 | decoder.layers.8            | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 115 | decoder.layers.8            | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 116 | decoder.layers.8.self_attn  | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 117 | decoder.layers.8.self_attn  | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 118 | decoder.layers.8.self_attn  | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 119 | decoder.layers.8.self_attn  | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 120 | decoder.layers.9            | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
| 121 | decoder.layers.9            | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
| 122 | decoder.layers.9            | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 123 | decoder.layers.9            | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 124 | decoder.layers.9            | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 125 | decoder.layers.9            | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 126 | decoder.layers.9.self_attn  | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 127 | decoder.layers.9.self_attn  | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 128 | decoder.layers.9.self_attn  | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 129 | decoder.layers.9.self_attn  | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 130 | decoder.layers.10           | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
| 131 | decoder.layers.10           | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
| 132 | decoder.layers.10           | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 133 | decoder.layers.10           | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 134 | decoder.layers.10           | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 135 | decoder.layers.10           | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 136 | decoder.layers.10.self_attn | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 137 | decoder.layers.10.self_attn | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 138 | decoder.layers.10.self_attn | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 139 | decoder.layers.10.self_attn | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 140 | decoder.layers.11           | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
| 141 | decoder.layers.11           | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
| 142 | decoder.layers.11           | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 143 | decoder.layers.11           | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 144 | decoder.layers.11           | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 145 | decoder.layers.11           | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 146 | decoder.layers.11.self_attn | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 147 | decoder.layers.11.self_attn | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 148 | decoder.layers.11.self_attn | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 149 | decoder.layers.11.self_attn | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 150 | decoder.layers.12           | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
| 151 | decoder.layers.12           | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
| 152 | decoder.layers.12           | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 153 | decoder.layers.12           | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 154 | decoder.layers.12           | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 155 | decoder.layers.12           | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 156 | decoder.layers.12.self_attn | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 157 | decoder.layers.12.self_attn | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 158 | decoder.layers.12.self_attn | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 159 | decoder.layers.12.self_attn | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 160 | decoder.layers.13           | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
| 161 | decoder.layers.13           | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
| 162 | decoder.layers.13           | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 163 | decoder.layers.13           | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 164 | decoder.layers.13           | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 165 | decoder.layers.13           | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 166 | decoder.layers.13.self_attn | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 167 | decoder.layers.13.self_attn | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 168 | decoder.layers.13.self_attn | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 169 | decoder.layers.13.self_attn | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 170 | decoder.layers.14           | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
| 171 | decoder.layers.14           | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
| 172 | decoder.layers.14           | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 173 | decoder.layers.14           | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 174 | decoder.layers.14           | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 175 | decoder.layers.14           | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 176 | decoder.layers.14.self_attn | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 177 | decoder.layers.14.self_attn | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 178 | decoder.layers.14.self_attn | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 179 | decoder.layers.14.self_attn | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 180 | decoder.layers.15           | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
| 181 | decoder.layers.15           | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
| 182 | decoder.layers.15           | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 183 | decoder.layers.15           | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 184 | decoder.layers.15           | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 185 | decoder.layers.15           | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 186 | decoder.layers.15.self_attn | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 187 | decoder.layers.15.self_attn | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 188 | decoder.layers.15.self_attn | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 189 | decoder.layers.15.self_attn | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 190 | decoder.layers.16           | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
| 191 | decoder.layers.16           | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
| 192 | decoder.layers.16           | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 193 | decoder.layers.16           | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 194 | decoder.layers.16           | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 195 | decoder.layers.16           | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 196 | decoder.layers.16.self_attn | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 197 | decoder.layers.16.self_attn | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 198 | decoder.layers.16.self_attn | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 199 | decoder.layers.16.self_attn | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 200 | decoder.layers.17           | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
| 201 | decoder.layers.17           | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
| 202 | decoder.layers.17           | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 203 | decoder.layers.17           | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 204 | decoder.layers.17           | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 205 | decoder.layers.17           | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 206 | decoder.layers.17.self_attn | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 207 | decoder.layers.17.self_attn | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 208 | decoder.layers.17.self_attn | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 209 | decoder.layers.17.self_attn | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 210 | decoder.layers.18           | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
| 211 | decoder.layers.18           | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
| 212 | decoder.layers.18           | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 213 | decoder.layers.18           | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 214 | decoder.layers.18           | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 215 | decoder.layers.18           | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 216 | decoder.layers.18.self_attn | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 217 | decoder.layers.18.self_attn | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 218 | decoder.layers.18.self_attn | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 219 | decoder.layers.18.self_attn | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 220 | decoder.layers.19           | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
| 221 | decoder.layers.19           | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
| 222 | decoder.layers.19           | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 223 | decoder.layers.19           | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 224 | decoder.layers.19           | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 225 | decoder.layers.19           | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 226 | decoder.layers.19.self_attn | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 227 | decoder.layers.19.self_attn | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 228 | decoder.layers.19.self_attn | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 229 | decoder.layers.19.self_attn | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 230 | decoder.layers.20           | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
| 231 | decoder.layers.20           | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
| 232 | decoder.layers.20           | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 233 | decoder.layers.20           | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 234 | decoder.layers.20           | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 235 | decoder.layers.20           | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 236 | decoder.layers.20.self_attn | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 237 | decoder.layers.20.self_attn | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 238 | decoder.layers.20.self_attn | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 239 | decoder.layers.20.self_attn | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 240 | decoder.layers.21           | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
| 241 | decoder.layers.21           | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
| 242 | decoder.layers.21           | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 243 | decoder.layers.21           | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 244 | decoder.layers.21           | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 245 | decoder.layers.21           | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 246 | decoder.layers.21.self_attn | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 247 | decoder.layers.21.self_attn | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 248 | decoder.layers.21.self_attn | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 249 | decoder.layers.21.self_attn | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 250 | decoder.layers.22           | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
| 251 | decoder.layers.22           | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
| 252 | decoder.layers.22           | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 253 | decoder.layers.22           | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 254 | decoder.layers.22           | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 255 | decoder.layers.22           | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 256 | decoder.layers.22.self_attn | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 257 | decoder.layers.22.self_attn | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 258 | decoder.layers.22.self_attn | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 259 | decoder.layers.22.self_attn | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 260 | decoder.layers.23           | self_attn            | <class 'transformers.models.opt.modeling_opt.OPTAttention'>                  | False           | False       |
| 261 | decoder.layers.23           | activation_fn        | <class 'torch.nn.modules.activation.ReLU'>                                   | False           | False       |
| 262 | decoder.layers.23           | self_attn_layer_norm | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 263 | decoder.layers.23           | fc1                  | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 264 | decoder.layers.23           | fc2                  | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 265 | decoder.layers.23           | final_layer_norm     | <class 'torch.nn.modules.normalization.LayerNorm'>                           | False           | False       |
| 266 | decoder.layers.23.self_attn | k_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 267 | decoder.layers.23.self_attn | v_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | True            | True        |
| 268 | decoder.layers.23.self_attn | q_proj               | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |
| 269 | decoder.layers.23.self_attn | out_proj             | <class 'torch.nn.modules.linear.Linear'>                                     | False           | True        |